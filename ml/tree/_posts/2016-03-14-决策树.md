---
title: "决策树学习"
description: "决策树学习"
layout: post
date: 2016-03-14 14:23:44 +0800
categories: [tree]
tags: [tree, jekyll]
comments: yes
---
决策树学习

ID3, 信息增益：算法过程参见周志华《机器学习》P75

> 信息熵： $ Entrpgy(S) = - \sum_{i=1}^N {p(u_i)log_2p(u_i)} $
> 信息增益： $ infoGain(S,A) = Entrpgy(S) - \sum_{v\in Value(A)} {\frac {\vert{S_v}\vert}{\vert{S}\vert}  Entrpgy(S)} $

ID3的主要缺点是对可取值数目较多的属性有所偏好，C4.5解决了这个问题。

C4.5, 信息增益率 ：

> 信息增益率： $ SplitInfo_A(S,A) =  - \sum_{j=1}^m {\frac {\vert{S_j}\vert}{\vert{S}\vert}log_2\frac {\vert{S_j}\vert}{\vert{S}\vert}} $

去掉了‘信息增益’，使用‘增益率’来划分。但是这样会对可取值数目较少的属性有所偏好，所以要用启发式,先从候选划分属性中找到信息增益高于评价水平的属性，再从中选择增益率最高的。

CART决策树； 剪枝（防止过拟合）；补充缺失值； 多变量决策

在数据挖掘中，决策树主要有两种类型:

分类树 的输出是样本的类标。回归树 的输出是一个实数 (例如房子的价格，病人呆在医院的时间等)。
