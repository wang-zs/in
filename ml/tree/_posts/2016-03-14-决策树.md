---
title: "决策树学习"
description: "决策树学习"
layout: post
date: 2016-03-14 14:23:44 +0800
categories: [tree]
tags: [tree, jekyll]
comments: yes
---
决策树学习

https://blog.csdn.net/zjsghww/article/details/51638126

ID3, 信息增益：算法过程参见周志华《机器学习》P75

> 信息熵： $ Entrpgy(S) = - \sum_{i=1}^N {p(u_i)log_2p(u_i)} $

> 信息增益： $ infoGain(S,A) = Entrpgy(S) - \sum_{v\in Value(A)} {\frac {\vert{S_v}\vert}{\vert{S}\vert}  Entrpgy(S)} $

<a href='https://classroom.udacity.com/nanodegrees/nd009-cn-preview/parts/d88d49be-6d08-43b2-90da-29de3603d321/modules/9a2f317e-48d2-4f9f-894b-4ce362b18720/lessons/a31de5d2-25c3-4fdb-b4f4-5a15770ff888/concepts/e964511f-92b0-4d11-a3df-3a1b1262cc8d'>sklearn 决策树</a> 阅读

ID3的主要缺点是对可取值数目较多的属性有所偏好，C4.5解决了这个问题。

C4.5, 信息增益率 ：

> 信息增益率： $ SplitInfo_A(S,A) =  - \sum_{j=1}^m {\frac {\vert{S_j}\vert}{\vert{S}\vert}log_2\frac {\vert{S_j}\vert}{\vert{S}\vert}} $

去掉了‘信息增益’，使用‘增益率’来划分。但是这样会对可取值数目较少的属性有所偏好，所以要用启发式,先从候选划分属性中找到信息增益高于评价水平的属性，再从中选择增益率最高的。

CART决策树； 剪枝（防止过拟合）；补充缺失值； 多变量决策
