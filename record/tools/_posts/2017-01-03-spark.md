---
title: "spark性能优化"
description: "tools"
layout: post
date: 2017-01-04 03:23:44 +0800
categories: [tools]
tags: [jekyll, github]
comments: yes
---
1，运行节点参数

我们在提交任务的时候，需要指定运行节点的数量，申请更多的节点就意味着更多的资源。

在spark-submit中，可以指定参数有两种命令方式：

1）--num-executors 600；指定申请节点数。

2）--conf "spark.dynamicAllocation.minExecutors=10" --conf "spark.dynamicAllocation.maxExecutors=600"；这样可以动态的申请节点数，在不使用的时候释放节点资源，但是在spark2.0之前有bug，在数据量过大的时候，会在节点的销毁和申请的消息通信卡住，导致程序一直卡住不动或者失败。

PS：一个节点默认占据6个CPU核。--executor-cores=XX 可以改变每个节点的CPU核数。

(44 + 6) / 50

44指的是已经跑完的task，6指的是申请的core数，通常为num-executors*executor-cores，50为partition数。

这儿只有6是因为只剩下6个task待执行完，所以需要6个core。

2，数据倾斜

数据倾斜简单的来说就是一个partition中的数据量远比其他的partition的数据量，运行的时间比其他partition的时间长。

可以用rdd.sample(false, 0.1).countByKey().foreach(println)来查看是否有一些key导致了倾斜。
数据倾斜的解决方式包括

1）过滤倾斜的数据；

2）增加random参数将key离散化；

等等

3，REPARTITION

task 的个数与stage 中上一个RDD 的partition 个数相同。

一般来说，partition建议是6的倍数，因为--executor-cores=默认是6。

从hive或者textFile中取出来的partition数等于hdfs的文件数。

每一次core只能处理一个partition的数据，太小了会导致每片数据量太大，导致内存压力，甚至是OOM失败，或者诸多executor的计算能力无法利用充分；但是如果太大了则会导致分片太多，执行效率降低。

partition要比num-executors*executor-cores更大，这样才能充分的利用资源。

partition最大不要超过50000。

所以，合适的partition需要根据程序的运算流程和资源的数量来设置。要是没有想法，可以先设成9600试试。

文件保存

在saveAsTextFile前，需要减少结果rdd的partition数目，这样会计算hdfs上的结果文件数，降低小文件数会降低hdfs namenode的压力，也会减少最后我们收集结果文件的时间。

val resultRDD = ... resultRDD.repartition(10).saveAsTextFile(output)
这里使用repartition()不使用coalesce()，是为了不降低resultRDD计算的并发量，通过再做一次shuffle将结果进行汇总。

合理的repartition得到的数据每个part文件的大小在100MB左右。

4，cache

RDD的cache()方法其实调用的就是persist方法，缓存策略均为MEMORY_ONLY。

cache操作只推荐在rdd在流中被多次使用的时候使用，比如rdd需要做count和reduce两个操作。

cache操作会直接把数据放在内存中，不要把大量的数据cache住，这样可能会导致内存不足。

5，groupBy可以用reduceByKey代替操作

这一条应该是比较经典的了。reduceByKey会在当前节点（local）中做reduce操作，也就是说，会在shuffle前，尽可能地减小数据量。而groupByKey则不是，它会不做任何处理而直接去shuffle。

可以这么写

result.map(x => (x.driver_id, Array(x))).reduceByKey((x,y) => x++y)
有一些类似的xxxByKey操作，都比groupByKey好，比如foldByKey和aggregateByKey。
另外，还有一条类似的是用treeReduce来代替reduce，主要是用于单个reduce操作开销比较大，可以条件treeReduce的深度来控制每次reduce的规模。

6，join可以用broadcast + filter代替

这种优化是一种特定场景的神器，就是拿大的RDD A去join一个小的RDD B：

A.join(B).map() 
可以改成
val b = sc.broadcast(B.collectAsMap)
A.map().filter()
一次shuffle都没有，A老老实实待着不动，等着全量的B被分发过来。
另外，在Spark SQL里面直接有BroadcastHashJoin，也是把小的rdd广播出去。



